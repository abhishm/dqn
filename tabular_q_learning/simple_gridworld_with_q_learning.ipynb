{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from q_learning import TabularQAgent\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#automatic reloading\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def rolling_average(a, n=3):\n",
    "    ret = []\n",
    "    t = 0\n",
    "    while t < len(a):\n",
    "        ret.append(np.mean(a[t:t+n]))\n",
    "        t += n\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3x3 Grid World (Modifying the Open-ai Frozen Lake environment to create a grid-world problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-07-31 15:09:23,922] Making new env: GridWorld-v0\n"
     ]
    }
   ],
   "source": [
    "from gym.envs.registration import register, spec\n",
    "MY_ENV_NAME='GridWorld-v0'\n",
    "try:\n",
    "    spec(MY_ENV_NAME)\n",
    "except:\n",
    "    register(\n",
    "        id=MY_ENV_NAME,\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={\"desc\":[\"SFF\", \"FFF\", \"FFG\"], \"map_name\": \"3x3\", \"is_slippery\": False}\n",
    "    )\n",
    "env = gym.make(MY_ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def modify_reward(transition, reward_map=lambda x: x - 1):\n",
    "    new_transition = [list(transition[0])]\n",
    "    new_transition[0][2] = reward_map(new_transition[0][3])\n",
    "    new_transition[0] = tuple(new_transition[0])\n",
    "    return new_transition\n",
    "\n",
    "for key, value in list(env.P.items()):\n",
    "    env.P[key] = {k: modify_reward(v) for k, v in value.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_agent = TabularQAgent(env.observation_space, env.action_space, discount=1.0, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm reached to goal 1000 times in 1000 number of episodes during learning phase.\n"
     ]
    }
   ],
   "source": [
    "t = q_agent.learn(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function q_learning.TabularQAgent.__init__.<locals>.<lambda>>,\n",
       "            {0: array([-3.5539762 , -3.        , -3.        , -3.74089437]),\n",
       "             1: array([-2.84263632, -2.        , -2.        , -2.60480864]),\n",
       "             2: array([-1.84115177, -1.        , -1.56467376, -1.18999996]),\n",
       "             3: array([-2.56940582, -2.        , -2.        , -3.05363067]),\n",
       "             4: array([-2.48572871, -1.        , -1.        , -2.07048336]),\n",
       "             5: array([-1.09118746,  0.        , -0.468559  , -0.54035473]),\n",
       "             6: array([-1.19      , -1.27099958, -1.        , -1.72325   ]),\n",
       "             7: array([-0.87802789, -0.71757046,  0.        , -1.29973816])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_agent.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
